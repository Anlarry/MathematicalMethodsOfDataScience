\chapter{背景}
    世界知名的亚马逊公司创建了在线市场并且为客户提供了对购买进行评级和审查的
机会。用户可以通过个人星级评级——从1星级到5星级来表示他们对产品的满意度，此外
，用户也可以通过提交文本信息来进行评论，从而进一步表达对待产品的看法和一些更
加具体的意见。用户除了直接针对商品进行评级和评价之外也可以针对其他用户的一些
评论进行评级，来表达他们认为这些评论是否对自己购买产品有帮助——从而使在线市场
能够筛选出有帮助的评论。

    而参与在线市场的产品营销公司则可以通过用户的各种数据数据来洞察他们是否应
该参与相关的市场和以及具体的参与时机，这也可以帮助他们对如何设计更受用户欢迎
的更成功的产品。

    如今，阳光公司正在计划在网上市场推出三种新产品：微波炉，婴儿奶嘴和吹风机。
他们聘请我们作为营销团队的顾问。要求我们通过过去用户提供的与其他竞争产品相关
的一些评论评级信息来为公司的在线销售战略提供信息，并且确定潜在的重要设计功能，
从而增强产品的受欢迎程度。公司曾经使用过数据来为销售战略提供信息，但是并没有
使用过特定的组合和类型的数据，他们表示对于这些数据中基于事件的模式非常感兴趣，
并且希望能够得到有助于公司制作出成功的产品的方式。
阳光数据中心为我们提供了这个项目的三个数据文件：\texttt{hair\_dryer.tsv}，
\texttt{microwave.tsv}和\texttt{pacifier.tsv}。
这些数据包括了用户对亚马逊市场中销售的微波炉，婴儿安抚奶嘴和吹风机在一定时间段内的评级和评论信息，希
望我们通过这些数据，使用数据科学的相关方法，利用星级评级，评论和评论评级之间的关系和衡量标准等解决一
些具体问题或实现一些具体需求：
\begin{enumerate}
    \item 阳光公司的三种产品一旦在在线市场上线，希望能够根据评级和评论确定出最具信息量的数据衡量标准帮助公司跟踪
    \item 在每个数据集中识别并讨论基于时间的度量和模式，这些度量和模式可以表明产品在在线市场的声誉上升或下降
    \item 确定基于文本的衡量标准与基于评级的衡量标准的组合，从而能够更好的指示潜在的成功产品或失败产品
    \item 具体的星级评分能够带来怎样的影响，是否会引发更多的评论，客户在看到低星级评级后是否会撰写某种类型的评论
    \item 基于文本的评论的具体质量描述来判断其是否与评级等级息息相关
\end{enumerate}


\chapter{方法}
基于所提供的数据集，我们将每一条信息分为如下的维度：

\begin{description}
    \item [文本] 每一条评论的文字中都包含了丰富的语义信息。虽然文本信息是非结构
        化，非数字化的，但现在数据科学领域内有着大量成熟的{\fKai 自然语言处
        理}技术，通过一系列算法的变换后，可以得到包含语义信息的数值化数据。
    \item [时间] 商品的声誉并非是静态的，而是随着时间变化的。数据集中给出了每一
        条评论的时间戳，通过结合其他数据维度，可以获得数据之间的时序关联。
    \item [评分] 评分是用户对产品评价最基本的数值度量，平均评分也是最为容易取得
        的可靠指标。
    \item [评价数] 出于合理的推断，我们假设一个商品的评价量$C$总是占总销售量$S$的一
        个固定比例，即满足$C/S=\textrm{const}$。又因为销售量和产品营收成直接的正
        相关关系，所以评价数也可以作为一个重要的指标。
\end{description}

在经过基础的数据处理后，我们对不同维度的指标做交叉分析。基本的流程框图
如\autoref{fig:schedule} 所示。

\begin{figure}
    \centering
    \includegraphics[height=0.3\paperwidth]{figure1.png}
    \caption{总流程}
    \label{fig:schedule}
\end{figure}


\section{文本处理}

\begin{figure}
    \centering
    \includegraphics[height=0.3\paperwidth]{figure1.png}
    \caption{文本处理流程}
    \label{fig:text-schedule}
\end{figure}

本文拟采用分词，关键字提取，文本向量化等方法对文本进行处理，以得到便于计算的向量
值。基本流程图见\autoref{fig:text-schedule}。

\subsection{分词（Tokenization）}
数据集中存在的文本是英文文本，可以……
我们使用自然语言处理库NLTK\ucite{loper2002nltk}的\texttt{tokenize}函数来进行处理。
该函数和的分词方法和PTB语料库的分词方法一致,\texttt{Treebank}标记生成器使用正则表达式对文本进
行标记化。该过程由调用的方法\texttt{word_tokenize()}。假设文本已经被分割成句子，则使用\texttt{sent_tokenize()}
来进行操作

该标记器执行以下步骤：
\begin{enumerate}
\item 分割标准收缩，例如将\texttt{don't}转化为\texttt{do n't}
\item 将大多数标点符号视为单独的标记进行分割
\item 分隔逗号和单引号以及句末的空格
\item 若出现了行末的单独的句点，将其分割开
\end{enumerate}

\subsection{文本清洗（Text Preprocessing）}
数据集中的用户评论文本是非结构化的复杂数据，有许多干扰因素。
在利用自然语言算法进行进一步处理之前，需要对文本进行清洗操作。

首先要去除非文本字符和标记。在文档中含有用于在网页上渲染格式的HTML标记
\texttt{<br/>}，以及用于显示视频的\texttt{[[img:]]} 标记等。这些字符对于语义分析
和自然语言处理算法都没有价值，应当予以去除。

接下来考虑词汇的同一性的问题。英语单词在句首时需要大写首字母，但是这样的变化并不
带有语义信息；同时英语属于拉丁语系，单词具有不同的屈折变化（Inflection）。不同的
屈折变化语义相近，应该做合并处理。为了方便计算机处理，我们对单词做{\fKai
标准化} （Normalization）处理，将大写字母转换为小写，并使用NLTK库的{\fKai 词性还
原}功能进行处理。这样标准化之后的词汇可以直接用字符串比较来判断同一性。

\subsection{关键词提取}
常见的关键词提取方法有……

\subsection{文本向量化}

\section{评分与文本的关联聚类}

\chapter{结果}

\chapter{总结}

\endinput

